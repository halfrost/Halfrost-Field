{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.halfrost.com/Blog/ArticleImage/78_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸€. Motivation\n",
    "\n",
    "\n",
    "æˆ‘ä»¬å¾ˆå¸Œæœ›æœ‰è¶³å¤Ÿå¤šçš„ç‰¹å¾ï¼ˆçŸ¥è¯†ï¼‰æ¥ä¿å‡†å­¦ä¹ æ¨¡åž‹çš„è®­ç»ƒæ•ˆæžœï¼Œå°¤å…¶åœ¨å›¾åƒå¤„ç†è¿™ç±»çš„ä»»åŠ¡ä¸­ï¼Œé«˜ç»´ç‰¹å¾æ˜¯åœ¨æ‰€éš¾å…çš„ï¼Œä½†æ˜¯ï¼Œé«˜ç»´çš„ç‰¹å¾ä¹Ÿæœ‰å‡ ä¸ªå¦‚ä¸‹ä¸å¥½çš„åœ°æ–¹ï¼š\n",
    "\n",
    "1. å­¦ä¹ æ€§èƒ½ä¸‹é™ï¼ŒçŸ¥è¯†è¶Šå¤šï¼Œå¸æ”¶çŸ¥è¯†ï¼ˆè¾“å…¥ï¼‰ï¼Œå¹¶ä¸”ç²¾é€šçŸ¥è¯†ï¼ˆå­¦ä¹ ï¼‰çš„é€Ÿåº¦å°±è¶Šæ…¢ã€‚\n",
    "2. è¿‡å¤šçš„ç‰¹å¾éš¾äºŽåˆ†è¾¨ï¼Œä½ å¾ˆéš¾ç¬¬ä¸€æ—¶é—´è®¤è¯†æŸä¸ªç‰¹å¾ä»£è¡¨çš„æ„ä¹‰ã€‚\n",
    "3. ç‰¹å¾å†—ä½™ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒåŽ˜ç±³å’Œè‹±å°ºå°±æ˜¯ä¸€å¯¹å†—ä½™ç‰¹å¾ï¼Œä»–ä»¬æœ¬èº«ä»£è¡¨çš„æ„ä¹‰æ˜¯ä¸€æ ·çš„ï¼Œå¹¶ä¸”èƒ½å¤Ÿç›¸äº’è½¬æ¢ã€‚\n",
    "\n",
    "![](https://img.halfrost.com/Blog/ArticleImage/78_1.png)\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨çŽ°åœ¨ä½¿ç”¨äº†ä¸€æ¡ç»¿è‰²ç›´çº¿ï¼Œå°†å„ä¸ªæ ·æœ¬æŠ•å½±åˆ°è¯¥ç›´çº¿ï¼Œé‚£ä¹ˆï¼ŒåŽŸæ¥äºŒç»´çš„ç‰¹å¾  x=(åŽ˜ç±³ï¼Œè‹±å°º)  å°±è¢«é™ä½Žä¸ºäº†ä¸€ç»´  x=(ç›´çº¿ä¸Šçš„ç›¸å¯¹ä½ç½®)\n",
    "\n",
    "![](https://img.halfrost.com/Blog/ArticleImage/78_2.png)\n",
    "\n",
    "è€Œåœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åˆå°†ä¸‰ç»´ç‰¹å¾æŠ•å½±åˆ°äºŒä½å¹³é¢ï¼Œä»Žè€Œå°†ä¸‰ç»´ç‰¹å¾é™åˆ°äº†äºŒç»´ï¼š\n",
    "\n",
    "![](https://img.halfrost.com/Blog/ArticleImage/78_3.png)\n",
    "\n",
    "ç‰¹å¾é™ç»´çš„ä¸€èˆ¬æ‰‹æ®µå°±æ˜¯å°†é«˜ç»´ç‰¹å¾æŠ•å½±åˆ°ä½Žç»´ç©ºé—´ã€‚\n",
    "\n",
    "\n",
    "é™ç»´çš„åŠ¨æœºæœ‰ä¸¤ä¸ªï¼š\n",
    "\n",
    "1. åŽ‹ç¼©æ•°æ®\n",
    "2. æ•°æ®å¯è§†åŒ–\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äºŒ. Principal Component Analysis ä¸»æˆåˆ†åˆ†æž\n",
    "\n",
    "PCAï¼ŒPrinciple Component Analysisï¼Œå³ä¸»æˆåˆ†åˆ†æžæ³•ï¼Œæ˜¯ç‰¹å¾é™ç»´çš„æœ€å¸¸ç”¨æ‰‹æ®µã€‚é¡¾åæ€ä¹‰ï¼ŒPCA èƒ½ä»Žå†—ä½™ç‰¹å¾ä¸­æå–ä¸»è¦æˆåˆ†ï¼Œåœ¨ä¸å¤ªæŸå¤±æ¨¡åž‹è´¨é‡çš„æƒ…å†µä¸‹ï¼Œæå‡äº†æ¨¡åž‹è®­ç»ƒé€Ÿåº¦ã€‚\n",
    "\n",
    "![](https://img.halfrost.com/Blog/ArticleImage/78_4.png)\n",
    "\n",
    "å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬å°†æ ·æœ¬åˆ°çº¢è‰²å‘é‡çš„è·ç¦»ç§°ä½œæ˜¯æŠ•å½±è¯¯å·®ï¼ˆProjection Errorï¼‰ã€‚ä»¥äºŒç»´æŠ•å½±åˆ°ä¸€ç»´ä¸ºä¾‹ï¼ŒPCA å°±æ˜¯è¦æ‰¾å¯»ä¸€æ¡ç›´çº¿ï¼Œä½¿å¾—å„ä¸ªç‰¹å¾çš„æŠ•å½±è¯¯å·®è¶³å¤Ÿå°ï¼Œè¿™æ ·æ‰èƒ½å°½å¯èƒ½çš„ä¿ç•™åŽŸç‰¹å¾å…·æœ‰çš„ä¿¡æ¯ã€‚\n",
    "\n",
    "å‡è®¾æˆ‘ä»¬è¦å°†ç‰¹å¾ä»Ž  n  ç»´åº¦é™åˆ°  k  ç»´ï¼šPCA é¦–å…ˆæ‰¾å¯»  k  ä¸ª  n  ç»´å‘é‡ï¼Œç„¶åŽå°†ç‰¹å¾æŠ•å½±åˆ°è¿™äº›å‘é‡æž„æˆçš„  k ç»´ç©ºé—´ï¼Œå¹¶ä¿è¯æŠ•å½±è¯¯å·®è¶³å¤Ÿå°ã€‚ä¸‹å›¾ä¸­ä¸­ï¼Œä¸ºäº†å°†ç‰¹å¾ç»´åº¦ä»Žä¸‰ç»´é™ä½Žåˆ°äºŒä½ï¼ŒPCA å°±ä¼šå…ˆæ‰¾å¯»ä¸¤ä¸ªä¸‰ç»´å‘é‡  $\\mu^{(1)},\\mu^{(2)}$ ï¼ŒäºŒè€…æž„æˆäº†ä¸€ä¸ªäºŒç»´å¹³é¢ï¼Œç„¶åŽå°†åŽŸæ¥çš„ä¸‰ç»´ç‰¹å¾æŠ•å½±åˆ°è¯¥äºŒç»´å¹³é¢ä¸Šï¼š\n",
    "\n",
    "\n",
    "![](https://img.halfrost.com/Blog/ArticleImage/78_5.png)\n",
    "\n",
    "\n",
    "### 1. åŒºåˆ«\n",
    "\n",
    "PCA å’Œ çº¿æ€§å›žå½’çš„åŒºåˆ«æ˜¯ï¼š\n",
    "\n",
    "\n",
    "![](https://img.halfrost.com/Blog/ArticleImage/78_3_.png)\n",
    "\n",
    "çº¿æ€§å›žå½’æ‰¾çš„æ˜¯åž‚ç›´äºŽ X è½´è·ç¦»æœ€å°å€¼ï¼ŒPCA æ‰¾çš„æ˜¯æŠ•å½±åž‚ç›´è·ç¦»æœ€å°å€¼ã€‚\n",
    "\n",
    "çº¿æ€§å›žå½’ç›®çš„æ˜¯æƒ³é€šè¿‡ x é¢„æµ‹ yï¼Œä½†æ˜¯ PCA çš„ç›®çš„æ˜¯ä¸ºäº†æ‰¾ä¸€ä¸ªé™ç»´çš„é¢ï¼Œæ²¡æœ‰ä»€ä¹ˆç‰¹æ®Šçš„ yï¼Œä»£è¡¨é™ç»´çš„é¢çš„å‘é‡ $x_1$ã€$x_2$ã€$x_3$ã€$x_n$ éƒ½æ˜¯åŒç­‰åœ°ä½çš„ã€‚\n",
    "\n",
    "\n",
    "### 2. ç®—æ³•æµç¨‹\n",
    "\n",
    "å‡å®šæˆ‘ä»¬éœ€è¦å°†ç‰¹å¾ç»´åº¦ä»Ž n ç»´é™åˆ° k ç»´ã€‚åˆ™ PCA çš„æ‰§è¡Œæµç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "ç‰¹å¾æ ‡å‡†åŒ–ï¼Œå¹³è¡¡å„ä¸ªç‰¹å¾å°ºåº¦ï¼š\n",
    "\n",
    "$$x^{(i)}_j=\\frac{x^{(i)}_j-\\mu_j}{s_j}$$\n",
    "\n",
    "$\\mu_j$ ä¸ºç‰¹å¾ j çš„å‡å€¼ï¼Œsj ä¸ºç‰¹å¾ j çš„æ ‡å‡†å·®ã€‚\n",
    " \n",
    "è®¡ç®—åæ–¹å·®çŸ©é˜µ $\\Sigma $ ï¼š\n",
    "\n",
    "\n",
    "$$\\Sigma =\\frac{1}{m}\\sum_{i=1}{m}(x^{(i)})(x^{(i)})^T=\\frac{1}{m} \\cdot  X^TX$$\n",
    " \n",
    "é€šè¿‡å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰ï¼Œæ±‚å– $\\Sigma $  çš„ç‰¹å¾å‘é‡ï¼ˆeigenvectorsï¼‰ï¼š\n",
    "\n",
    "$$(U,S,V^T)=SVD(\\Sigma )$$\n",
    "\n",
    "\n",
    " \n",
    "ä»Ž U ä¸­å–å‡ºå‰ k ä¸ªå·¦å¥‡å¼‚å‘é‡ï¼Œæž„æˆä¸€ä¸ªçº¦å‡çŸ©é˜µ  Ureduce :\n",
    "\n",
    "$$U_{reduce}=(\\mu^{(1)},\\mu^{(2)},\\cdots,\\mu^{(k)})$$\n",
    " \n",
    "è®¡ç®—æ–°çš„ç‰¹å¾å‘é‡ï¼š $z^{(i)}$ \n",
    "\n",
    "$$z^{(i)}=U^{T}_{reduce} \\cdot  x^{(i)}$$\n",
    "\n",
    "\n",
    "### 3. ç‰¹å¾è¿˜åŽŸ\n",
    "\n",
    "å› ä¸º PCA ä»…ä¿ç•™äº†ç‰¹å¾çš„ä¸»æˆåˆ†ï¼Œæ‰€ä»¥ PCA æ˜¯ä¸€ç§æœ‰æŸçš„åŽ‹ç¼©æ–¹å¼ï¼Œå‡å®šæˆ‘ä»¬èŽ·å¾—æ–°ç‰¹å¾å‘é‡ä¸ºï¼š\n",
    "\n",
    "$$z=U^T_{reduce}x$$\n",
    " \n",
    "é‚£ä¹ˆï¼Œè¿˜åŽŸåŽçš„ç‰¹å¾ $x_{approx}$ ä¸ºï¼š\n",
    "\n",
    "$$x_{approx}=U_{reduce}z$$\n",
    "\n",
    "\n",
    "![](https://img.halfrost.com/Blog/ArticleImage/78_6.png)\n",
    "\n",
    "\n",
    "### 4. é™ç»´å¤šå°‘æ‰åˆé€‚ï¼Ÿ\n",
    "\n",
    "\n",
    "ä»Ž PCA çš„æ‰§è¡Œæµç¨‹ä¸­ï¼Œæˆ‘ä»¬çŸ¥é“ï¼Œéœ€è¦ä¸º PCA æŒ‡å®šç›®çš„ç»´åº¦ k ã€‚å¦‚æžœé™ç»´ä¸å¤šï¼Œåˆ™æ€§èƒ½æå‡ä¸å¤§ï¼›å¦‚æžœç›®æ ‡ç»´åº¦å¤ªå°ï¼Œåˆ™åˆä¸¢å¤±äº†è®¸å¤šä¿¡æ¯ã€‚é€šå¸¸ï¼Œä½¿ç”¨å¦‚ä¸‹çš„æµç¨‹çš„æ¥è¯„ä¼° k å€¼é€‰å–ä¼˜å¼‚ï¼š\n",
    "\n",
    "æ±‚å„æ ·æœ¬çš„æŠ•å½±å‡æ–¹è¯¯å·®:\n",
    "\n",
    "$$\\min \\frac{1}{m}\\sum_{j=1}^{m}\\left \\| x^{(i)}-x^{(i)}_{approx} \\right \\|^2$$\n",
    " \n",
    "æ±‚æ•°æ®çš„æ€»å˜å·®ï¼š\n",
    "\n",
    "$$\\frac{1}{m}\\sum_{j=1}^{m}\\left \\| x^{(i)} \\right \\|^2$$\n",
    " \n",
    "è¯„ä¼°ä¸‹å¼æ˜¯å¦æˆç«‹:\n",
    "\n",
    "$$\\frac{\\min \\frac{1}{m}\\sum_{j=1}^{m}\\left \\| x^{(i)}-x^{(i)}_{approx} \\right \\|^2}{\\frac{1}{m}\\sum_{j=1}^{m}\\left \\| x^{(i)} \\right \\|^2} \\leqslant \\epsilon $$\n",
    " \n",
    "å…¶ä¸­ï¼Œ $\\epsilon $  çš„å–å€¼å¯ä»¥ä¸º  0.01,0.05,0.10,â‹¯ï¼Œå‡è®¾  $\\epsilon = 0.01 $ ï¼Œæˆ‘ä»¬å°±è¯´â€œç‰¹å¾é—´ 99% çš„å·®å¼‚æ€§å¾—åˆ°ä¿ç•™â€ã€‚\n",
    "\n",
    "\n",
    "\n",
    "### 5. ä¸è¦æå‰ä¼˜åŒ–\n",
    "\n",
    "ç”±äºŽ PCA å‡å°äº†ç‰¹å¾ç»´åº¦ï¼Œå› è€Œä¹Ÿæœ‰å¯èƒ½å¸¦æ¥è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚PCA ä¸æ˜¯å¿…é¡»çš„ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä¸€å®šè°¨è®°ä¸è¦æå‰ä¼˜åŒ–ï¼Œåªæœ‰å½“ç®—æ³•è¿è¡Œæ•ˆçŽ‡ä¸å°½å¦‚å¦‚äººæ„æ—¶ï¼Œå†è€ƒè™‘ä½¿ç”¨ PCA æˆ–è€…å…¶ä»–ç‰¹å¾é™ç»´æ‰‹æ®µæ¥æå‡è®­ç»ƒé€Ÿåº¦ã€‚\n",
    "\n",
    "å½“ä½ åœ¨ä¿ç•™ 99% æˆ–è€… 95% æˆ–è€…å…¶å®ƒç™¾åˆ†æ¯”çš„æ–¹å·®æ—¶ï¼Œç»“æžœè¡¨æ˜Žï¼Œå°±åªä½¿ç”¨æ­£åˆ™åŒ–å°†ä¼šç»™ä½ ä¸€ç§é¿å…è¿‡æ‹Ÿåˆç»å¯¹å¥½çš„æ–¹æ³•ï¼ŒåŒæ—¶æ­£åˆ™åŒ–æ•ˆæžœä¹Ÿä¼šæ¯” PCA æ›´å¥½ å› ä¸ºå½“ä½ ä½¿ç”¨çº¿æ€§å›žå½’æˆ–è€…é€»è¾‘å›žå½’æˆ–å…¶ä»–çš„æ–¹æ³•ï¼Œé…åˆæ­£åˆ™åŒ–æ—¶ï¼Œè¿™ä¸ªæœ€å°åŒ–é—®é¢˜å®žé™…å°±å˜æˆäº† y å€¼æ˜¯ä»€ä¹ˆï¼Œæ‰ä¸è‡³äºŽå°†æœ‰ç”¨çš„ä¿¡æ¯èˆå¼ƒæŽ‰ã€‚ç„¶è€Œ PCA ä¸éœ€è¦ä½¿ç”¨åˆ°è¿™äº›æ ‡ç­¾æ›´å®¹æ˜“å°†æœ‰ä»·å€¼ä¿¡æ¯èˆå¼ƒæ€»ä¹‹ï¼Œä½¿ç”¨ PCA çš„ç›®çš„æ˜¯åŠ é€Ÿå­¦ä¹ ç®—æ³•çš„æ—¶å€™æ˜¯å¥½çš„ï¼Œä½†æ˜¯ç”¨å®ƒæ¥é¿å…è¿‡æ‹Ÿåˆï¼Œå´å¹¶ä¸æ˜¯ä¸€ä¸ªå¥½çš„ PCA åº”ç”¨ã€‚æˆ‘ä»¬ä½¿ç”¨æ­£åˆ™åŒ–çš„æ–¹æ³•æ¥ä»£æ›¿ PCA æ–¹æ³•æ˜¯å¾ˆå¤šäººå»ºè®®çš„ ã€‚\n",
    "\n",
    "**PCA ç”¨æ¥è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜æ˜¯é”™è¯¯çš„é€‰æ‹©ï¼Œè¯·è€ƒè™‘æ­£åˆ™åŒ–çš„æ–¹å¼è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜**ã€‚\n",
    "\n",
    "ä½ çš„å­¦ä¹ ç®—æ³•æ”¶æ•›åœ°éžå¸¸ç¼“æ…¢ï¼Œå ç”¨å†…å­˜æˆ–è€…ç¡¬ç›˜ç©ºé—´éžå¸¸å¤§ æ‰€ä»¥ä½ æƒ³æ¥åŽ‹ç¼©æ•°æ®ã€‚åªæœ‰å½“ä½ çš„ $x^{(i)}$ æ•ˆæžœä¸å¥½ï¼Œåªæœ‰å½“ä½ æœ‰è¯æ®æˆ–è€…ï¼Œå……è¶³çš„ç†ç”±æ¥ç¡®å®š $x^{(i)}$ æ•ˆæžœä¸å¥½çš„æ—¶å€™ï¼Œé‚£ä¹ˆå°±è€ƒè™‘ç”¨ PCA æ¥è¿›è¡ŒåŽ‹ç¼©æ•°æ®ã€‚\n",
    "\n",
    "\n",
    "PCA é€šå¸¸éƒ½æ˜¯è¢«ç”¨æ¥åŽ‹ç¼©æ•°æ®çš„ï¼Œä»¥å‡å°‘å†…å­˜ä½¿ç”¨æˆ–ç¡¬ç›˜ç©ºé—´å ç”¨ï¼Œæˆ–è€…ç”¨æ¥å¯è§†åŒ–æ•°æ®ã€‚\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‰. Principal Component Analysis æµ‹è¯•\n",
    "\n",
    "\n",
    "### 1. Question 1\n",
    "\n",
    "Consider the following 2D dataset:\n",
    "\n",
    "\n",
    "![](https://img.halfrost.com/Blog/ArticleImage/7X_1.png)\n",
    "\n",
    "Which of the following figures correspond to possible values that PCA may return for u(1) (the first eigenvector / first principal component)? Check all that apply (you may have to check more than one figure).\n",
    "\n",
    "\n",
    "\n",
    "A. ![](https://img.halfrost.com/Blog/ArticleImage/7X_1A.png)\n",
    "\n",
    "B. ![](https://img.halfrost.com/Blog/ArticleImage/7X_1B.png)\n",
    "\n",
    "C. ![](https://img.halfrost.com/Blog/ArticleImage/7X_1C.png)\n",
    "\n",
    "D. ![](https://img.halfrost.com/Blog/ArticleImage/7X_1D.png)\n",
    "\n",
    "\n",
    "è§£ç­”ï¼šAã€B\n",
    "\n",
    "\n",
    "### 2. Question 2\n",
    "\n",
    "Which of the following is a reasonable way to select the number of principal components k?\n",
    "\n",
    "(Recall that n is the dimensionality of the input data and m is the number of input examples.)\n",
    "\n",
    "\n",
    "A. Choose k to be the smallest value so that at least 1% of the variance is retained.\n",
    "\n",
    "B. Choose k to be the smallest value so that at least 99% of the variance is retained.\n",
    "\n",
    "C. Choose the value of k that minimizes the approximation error $\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} - x_{approx}^{(i)} \\right \\|^{2}$.\n",
    "\n",
    "D. Choose k to be 99% of n (i.e., k=0.99âˆ—n, rounded to the nearest integer).\n",
    "\n",
    "\n",
    "è§£ç­”ï¼š B\n",
    "\n",
    "### 3. Question 3\n",
    "\n",
    "Suppose someone tells you that they ran PCA in such a way that \"95% of the variance was retained.\" What is an equivalent statement to this?\n",
    "\n",
    "\n",
    "A. $\\frac{\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} \\right \\|^{2}}{\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} - x_{approx}^{(i)} \\right \\|^{2}} \\geqslant 0.05$\n",
    "\n",
    "B. $\\frac{\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} \\right \\|^{2}}{\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} - x_{approx}^{(i)} \\right \\|^{2}}  \\leqslant  0.95$\n",
    "\n",
    "C. $\\frac{\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} - x_{approx}^{(i)} \\right \\|^{2}}{\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} \\right \\|^{2}} \\leqslant 0.05$\n",
    "\n",
    "D. $\\frac{\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} \\right \\|^{2}}{\\frac{1}{m}\\sum^{m}_{i=1}\\left \\| x^{(i)} - x_{approx}^{(i)} \\right \\|^{2}} \\leqslant 0.05$\n",
    "\n",
    "è§£ç­”ï¼š C\n",
    "\n",
    "### 4. Question 4\n",
    "\n",
    "Which of the following statements are true? Check all that apply.\n",
    "\n",
    "\n",
    "A. If the input features are on very different scales, it is a good idea to perform feature scaling before applying PCA.\n",
    "\n",
    "B. Feature scaling is not useful for PCA, since the eigenvector calculation (such as using Octave's ðšœðšŸðš(ðš‚ðš’ðšðš–ðšŠ) routine) takes care of this automatically.\n",
    "\n",
    "C. Given an input $x \\in \\mathbb{R}^{n}$, PCA compresses it to a lower-dimensional vector $z \\in \\mathbb{R}^{k}$.\n",
    "\n",
    "D. PCA can be used only to reduce the dimensionality of data by 1 (such as 3D to 2D, or 2D to 1D).\n",
    "\n",
    "è§£ç­”ï¼šAã€C\n",
    "\n",
    "\n",
    "\n",
    "### 5. Question 5\n",
    "\n",
    "Which of the following are recommended applications of PCA? Select all that apply.\n",
    "\n",
    "\n",
    "A. To get more features to feed into a learning algorithm.\n",
    "\n",
    "B. Data compression: Reduce the dimension of your data, so that it takes up less memory / disk space.\n",
    "\n",
    "C. Data visualization: Reduce data to 2D (or 3D) so that it can be plotted.\n",
    "\n",
    "D. Data compression: Reduce the dimension of your input data $x^{(i)}$, which will be used in a supervised learning algorithm (i.e., use PCA so that your supervised learning algorithm runs faster).\n",
    "\n",
    "\n",
    "è§£ç­”ï¼šBã€C\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GitHub Repoï¼š[Halfrost-Field](https://github.com/halfrost/Halfrost-Field)\n",
    "> \n",
    "> Follow: [halfrost Â· GitHub](https://github.com/halfrost)\n",
    ">\n",
    "> Source: [https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine\\_Learning/Dimensionality\\_Reduction.ipynb](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Dimensionality_Reduction.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
